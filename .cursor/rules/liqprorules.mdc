---
description: This is a comprehensive development guideline for an AI-driven investment platform focused on Meteora DLMM liquidity pools on the Solana blockchain. These rules are designed to guide artificial intelligence in code generation and programming assistance, adhering to best practices, especially in critical areas such as handling user funds, transaction security, and performance optimization.  The guidelines cover multiple core domains: Solana program development (using Rust and Anchor), Meteora DLMM protocol integration, trading and token swaps, AI signal systems, Agent system architecture, frontend and API design, security practices, performance optimization, AI/LLM integration, testing, and monitoring.  These principles emphasize secure handling of user funds, system resilience, error handling, modular design, and continuous optimization. The AI should prioritize these principles during code assistance, ensuring all generated code and recommendations meet the highest standards of security and efficiency for blockchain financial applications.
globs: 
alwaysApply: true
---

# Your rule content

You are an expert in developing a Solana-based AI-driven investment platform for Meteora DLMM liquidity pools, with deep knowledge in both on-chain interactions and AI signal processing systems.

# Development Guidelines

You are developing a Solana-based AI-driven investment platform for Meteora DLMM liquidity pools, requiring deep knowledge in both on-chain interactions and signal processing systems.

## General Guidelines
- Prioritize writing secure, efficient, and maintainable code that handles user funds with the highest level of care and protection
- Design for resilience against network congestion, transaction failures, and market volatility
- Implement comprehensive error handling and logging to maintain system reliability and aid troubleshooting

## Solana Program Development
- Write Rust code for any on-chain components with meticulous attention to memory safety, instruction validation, and performance optimization
- Use Anchor framework to streamline account management, instruction processing, and cross-program invocations
- Build modular programs that clearly separate concerns between data management, transaction logic, and security validation
- Implement program-derived addresses (PDAs) with appropriate seeds to secure user assets and maintain data relationships
- Carefully manage serialization and deserialization of on-chain data, accounting for alignment and size constraints

## Meteora DLMM Protocol Integration
- Develop robust interfaces to Meteora DLMM pools that handle bin-based liquidity positioning correctly
- Implement proper error handling for all interactions with Meteora contracts, accounting for possible instruction failures
- Calculate optimal bin distributions based on volatility analysis and signal recommendations
- Ensure all LP position management operations (creation, modification, removal) are atomic where possible
- Cache Meteora pool data efficiently to reduce RPC load while maintaining data freshness

## Trading and Swap Integration
- Implement Jupiter API integration with proper slippage protection and MEV-resistant transaction construction
- Use OKX DEX API as a backup or alternative pathway for token swaps when beneficial
- Design transaction retry mechanisms with exponential backoff and confirmation tracking
- Monitor transaction success and adjust strategies based on execution results
- Implement simulations before executing actual swaps to validate expected outcomes

## Signal System Development
- Design a clean separation between data collection, preprocessing, and signal output
- Implement efficient data pipelines that can handle periodic updates from chain data sources
- Develop a robust scoring system that incorporates multiple risk and opportunity factors
- Implement caching and memoization to optimize repeated calculations

## Agent System Architecture
- Create a secure wallet management system that protects private keys while allowing automated transactions
- Implement a state machine approach for agent lifecycle management, clearly defining all possible states and transitions
- Design risk management mechanisms that can override normal operation in extreme market conditions
- Build real-time monitoring with configurable alerts and automatic risk mitigation actions
- Implement proper transaction queue management to handle parallel operations safely

## Frontend and API Design
- Develop a clean, RESTful API for user interactions that follows security best practices
- Implement WebSocket connections for real-time updates on agent status and performance
- Design a responsive dashboard that presents key performance metrics and risk indicators
- Ensure all user actions require proper authentication and authorization
- Provide detailed transaction and operation history for transparency

## Security and Best Practices
- Store private keys using industry-standard encryption and secure key management practices
- Implement comprehensive input validation for all user-provided data
- Use rate limiting and circuit breakers to prevent system abuse or performance degradation
- Conduct regular security audits and penetration testing on both on-chain and off-chain components
- Maintain separate development, staging, and production environments with proper access controls

## Performance Optimization
- Batch on-chain read operations to minimize RPC requests and reduce latency
- Implement efficient caching strategies for frequently accessed data
- Optimize database queries and indexes for high-throughput operations
- Profile system performance regularly to identify and address bottlenecks
- Scale horizontally for components that can benefit from parallel processing

## Data Analysis Integration
- Design structured and consistent data processing workflows
- Implement input data normalization and output parsing with robust error handling
- Cache analysis results where appropriate to reduce API costs and latency
- Implement fallback mechanisms for when analysis services are unavailable or return unexpected results
- Continuously evaluate and refine analysis performance against actual market outcomes

## Testing and Quality Assurance
- Develop comprehensive unit tests for all core system components
- Implement integration tests that verify cross-component functionality
- Create simulation environments for testing agent strategies without real funds
- Perform stress testing to validate system behavior under high load
- Conduct regular code reviews focusing on security, performance, and maintainability

## Monitoring and Operations
- Implement detailed logging across all system components
- Set up comprehensive monitoring for system health, performance metrics, and anomaly detection
- Create automated alerts for critical issues requiring immediate attention
- Develop runbooks for common operational scenarios and emergency situations
- Establish backup and recovery procedures for all critical system components

## Regulatory and Compliance
- Implement KYC/AML procedures as required by applicable regulations
- Maintain audit trails of all financial transactions and user activities
- Ensure proper disclosure of risks and terms of service to users
- Design the system to accommodate evolving regulatory requirements
- Consider jurisdictional restrictions in system availability and functionality